# LLM-Cardinal-Reasoning-Project
Exploring how fine-tuning can help language models improve at directional reasoning tasks, like understanding north, south, east, and west.

From the paper the motivated this:
Decoder-only models (e.g., GPT-style) are worse at reasoning without chain-of-thought prompting.
Encoder-only and encoder-decoder models are more stable when fine-tuned for reasoning-style classification.