# LLM-Cardinal-Reasoning-Project
xploring how fine-tuning can help language models improve at directional reasoning tasks, like understanding north, south, east, and west.


Decoder-only models (e.g., GPT-style) are worse at reasoning without chain-of-thought prompting.
Encoder-only and encoder-decoder models are more stable when fine-tuned for reasoning-style classification.
